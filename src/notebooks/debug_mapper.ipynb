{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc21a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 num_examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils.collators import collate_multitrack_paired\n",
    "from fx_model.apply_effects_multitrack_utils import multitrack_batched_processing\n",
    "import os\n",
    "from datasets.tency_mastering_multitrack_paired import TencyMastering_Test\n",
    "import omegaconf\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#from fx_model.fxnormaug_v3_noiseless import FxNormAug\n",
    "#randomizer=FxNormAug(sample_rate=44100, mode=\"train\", device=device )\n",
    "\n",
    "\n",
    "from fx_model.distribution_presets.uniform_RMSnorm import get_distributions_uniform\n",
    "from fx_model.fx_pipeline import EffectRandomizer\n",
    "\n",
    "distribution_uniform = get_distributions_uniform(sample_rate=44100)\n",
    "effect_randomizer_uniform=EffectRandomizer(sample_rate=44100, distributions_dict=distribution_uniform, device=device)\n",
    "\n",
    "normalize_params=omegaconf.OmegaConf.create(\n",
    "    {\n",
    "    \"normalize_mode\": \"rms_dry\",\n",
    "    \"rms_dry\": -25.0\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset_val= TencyMastering_Test(\n",
    "  mode= \"dry-wet\",\n",
    "  segment_length= 525312,\n",
    "  fs= 44100,\n",
    "  stereo= True,\n",
    "  tracks= \"all\",\n",
    "  num_tracks= 1,\n",
    "  path_csv= \"/data5/eloi/TencyMastering/PANNs_country_pop/val_split.csv\",\n",
    "  normalize_params=normalize_params,\n",
    "  num_examples= -1, #use all examples\n",
    "  RMS_threshold_dB= -40.0,\n",
    "  only_dry=True,\n",
    "  random_order=True,  #randomize the order of the samples\n",
    "  seed= 42\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "batch_size=32\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, num_workers=1, collate_fn=lambda x: x)\n",
    "\n",
    "\n",
    "outputs_dry = {}\n",
    "outputs_wet = {}\n",
    "for i,  data in enumerate(val_loader):\n",
    "\n",
    "    collated_data = collate_multitrack_paired(data)\n",
    "\n",
    "    x=collated_data['x'].to(device)  # x is a tensor of shape [B, N, C, L] where B is the batch size, N is the number of tracks, C is the number of channels and L is the length of the audio\n",
    "    taxonomy=collated_data['taxonomies']  # taxonomy is a list of lists of taxonomies, each list is a track, each taxonomy is a string of 2 digits\n",
    "    masks=collated_data['masks'].to(device)  # masks is a tensor of shape [B, N] where B is the batch size and N is the number of tracks, it is used to mask the tracks that are not present in the batch\n",
    "    paths=collated_data['paths']  # paths is a list of paths to the audio files, each path is a string\n",
    "\n",
    "\n",
    "    func = lambda x, taxonomy: effect_randomizer_uniform.forward(x) \n",
    "\n",
    "    y= multitrack_batched_processing(x.clone(), taxonomy=taxonomy, function=func, class_dependent=False, masks=masks)\n",
    "\n",
    "    outputs_dry[i] = x.cpu()\n",
    "    outputs_wet[i] = y.cpu()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc533e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mipd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_dry\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m44100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#outputs_dry[0].shape\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#outputs_wet[0].shape\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.11/site-packages/IPython/lib/display.py:130\u001b[39m, in \u001b[36mAudio.__init__\u001b[39m\u001b[34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[43mAudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_make_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.11/site-packages/IPython/lib/display.py:152\u001b[39m, in \u001b[36mAudio._make_wav\u001b[39m\u001b[34m(data, rate, normalize)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwave\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     scaled, nchan = \u001b[43mAudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_normalize_with_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    154\u001b[39m     scaled, nchan = Audio._validate_and_normalize_without_numpy(data, normalize)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/myenv/lib/python3.11/site-packages/IPython/lib/display.py:172\u001b[39m, in \u001b[36mAudio._validate_and_normalize_with_numpy\u001b[39m\u001b[34m(data, normalize)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_and_normalize_with_numpy\u001b[39m(data, normalize) -> Tuple[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data.shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    174\u001b[39m         nchan = \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(outputs_dry[0][0][0].numpy(), rate=44100)\n",
    "#outputs_dry[0].shape\n",
    "#outputs_wet[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
