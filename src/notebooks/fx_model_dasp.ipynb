{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7829480c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dry torch.Size([1, 1, 11065479]) tensor(-0.1188) tensor(0.1767)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eloi/myenv/lib/python3.11/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dry torch.Size([1, 1, 11065479]) tensor(-0.7274, device='cuda:0') tensor(1.0821, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "file_id=6448\n",
    "\n",
    "base_path=\"/home/eloi/projects/project_mfm_eloi/audio_examples/TM_val/\"\n",
    "file_dry=os.path.join(base_path, \"dry\",str(file_id),\"vocals.wav\")\n",
    "file_wet=os.path.join(base_path, \"wet\",str(file_id),\"vocals.wav\")\n",
    "\n",
    "file_dry_fxnorm=os.path.join(base_path,\"dry\", str(file_id), \"vocals_normalized.wav\")\n",
    "file_wet_fxnorm=os.path.join(base_path, \"wet\",str(file_id), \"vocals_normalized.wav\")\n",
    "\n",
    "file_dry_fxnorm_dr=os.path.join(base_path, \"dry\", str(file_id), \"vocals_normalized_dr.wav\")\n",
    "file_wet_fxnorm_dr=os.path.join(base_path, \"wet\",str(file_id),\"vocals_normalized_dr.wav\")\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "dry, sr = sf.read(file_dry)\n",
    "wet, sr = sf.read(file_wet)\n",
    "\n",
    "file_dry_fxnorm, sr=sf.read(file_dry_fxnorm_dr)\n",
    "file_wet_fxnorm, sr=sf.read(file_wet_fxnorm_dr)\n",
    "\n",
    "dry=torch.from_numpy(dry.T).float().unsqueeze(0)\n",
    "wet=torch.from_numpy(wet.T).float().unsqueeze(0)\n",
    "\n",
    "dry_fxnorm=torch.from_numpy(file_dry_fxnorm.T).float().unsqueeze(0)\n",
    "\n",
    "dry=dry.mean(dim=1, keepdim=True)\n",
    "\n",
    "dry_fxnorm=torch.from_numpy(file_dry_fxnorm.T).float().unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pyloudnorm as pyln\n",
    "meter = pyln.Meter(sr)\n",
    "normaliser = lambda x: pyln.normalize.loudness(\n",
    "    x, meter.integrated_loudness(x), -18.0\n",
    ")\n",
    "\n",
    "print(\"dry\", dry.shape, dry.min(), dry.max())\n",
    "\n",
    "dry = torch.from_numpy(normaliser(dry.numpy().T).T).float().to(device)\n",
    "#wet = torch.from_numpy(normaliser(wet.numpy().T).T).float().to(device)\n",
    "dry_fxnorm = torch.from_numpy(normaliser(dry_fxnorm.numpy().T).T).float().to(device)\n",
    "\n",
    "\n",
    "print(\"dry\", dry.shape,dry.min(), dry.max())\n",
    "\n",
    "start_t=15*sr\n",
    "segment_length = 525312\n",
    "dry_segment = dry[...,start_t:start_t + segment_length]\n",
    "wet_segment = wet[...,start_t:start_t + segment_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffdd7ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 11065479])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02628e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a6fe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eloi/myenv/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xout torch.Size([1, 1, 525312]) tensor(-0.3862, device='cuda:0', grad_fn=<MinBackward1>) tensor(0.3537, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from fx_model.dasp_diffvox import DASPDiffVox\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=DASPDiffVox(sample_rate=44100).to(device)\n",
    "\n",
    "xout=model(dry_segment.to(device))\n",
    "\n",
    "print(\"xout\", xout.shape, xout.min(), xout.max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
